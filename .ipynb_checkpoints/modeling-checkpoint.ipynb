{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "757d8370-4a22-4b88-a267-a4403adf3389",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a508c7f4-0051-46bb-8beb-d5551e88f146",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "import joblib\n",
    "import json\n",
    "import pandas as pd\n",
    "import copy\n",
    "import hashlib\n",
    "\n",
    "import src.util as util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac832ad-0994-4b1a-a851-ed1721c3e832",
   "metadata": {},
   "source": [
    "# 1. Load Config File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a64ed122-a590-4e7f-b428-3b905562fb28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = util.load_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c36414-76c8-41f9-aa42-663182414371",
   "metadata": {},
   "source": [
    "# 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f7a4876-d62a-44a3-b605-483f8ffafe9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_train_feng(params: dict) -> pd.DataFrame:\n",
    "    # Load train set\n",
    "    x_train = util.pickle_load(params[\"train_feng_set_path\"][0])\n",
    "    y_train = util.pickle_load(params[\"train_feng_set_path\"][1])\n",
    "\n",
    "    return x_train, y_train\n",
    "\n",
    "def load_valid_feng(params: dict) -> pd.DataFrame:\n",
    "    # Load valid set\n",
    "    x_valid = util.pickle_load(params[\"valid_feng_set_path\"][0])\n",
    "    y_valid = util.pickle_load(params[\"valid_feng_set_path\"][1])\n",
    "\n",
    "    return x_valid, y_valid\n",
    "\n",
    "def load_test_feng(params: dict) -> pd.DataFrame:\n",
    "    # Load test set\n",
    "    x_test = util.pickle_load(params[\"test_feng_set_path\"][0])\n",
    "    y_test = util.pickle_load(params[\"test_feng_set_path\"][1])\n",
    "\n",
    "    return x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d318c24-efa5-4d0b-aded-b735467a0ee5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_dataset(params: dict) -> pd.DataFrame:\n",
    "    # Debug message\n",
    "    util.print_debug(\"Loading dataset.\")\n",
    "\n",
    "    # Load train set\n",
    "    x_train, y_train = load_train_feng(params)\n",
    "\n",
    "    # Load valid set\n",
    "    x_valid, y_valid = load_valid_feng(params)\n",
    "\n",
    "    # Load test set\n",
    "    x_test, y_test = load_test_feng(params)\n",
    "\n",
    "    # Debug message\n",
    "    util.print_debug(\"Dataset loaded.\")\n",
    "\n",
    "    # Return the dataset\n",
    "    return x_train, y_train, x_valid, y_valid, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6865b719-49d2-44cc-8ccf-29f3a82a386e",
   "metadata": {},
   "source": [
    "# 3. Create Training Log Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec6cf0be-5e0d-432d-b003-0946f61aed69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training_log_template() -> dict:\n",
    "    # Debug message\n",
    "    util.print_debug(\"Creating training log template.\")\n",
    "    \n",
    "    # Template of training log\n",
    "    logger = {\n",
    "        \"model_name\" : [],\n",
    "        \"model_uid\" : [],\n",
    "        \"training_time\" : [],\n",
    "        \"training_date\" : [],\n",
    "        \"performance\" : [],\n",
    "        \"f1_score_avg\" : [],\n",
    "        \"data_configurations\" : [],\n",
    "    }\n",
    "\n",
    "    # Debug message\n",
    "    util.print_debug(\"Training log template created.\")\n",
    "\n",
    "    # Return training log template\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2809b3d2-5d95-48e6-9868-e2e8c7db5214",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training_log_updater(current_log: dict, params: dict) -> list:\n",
    "    # Create copy of current log\n",
    "    current_log = copy.deepcopy(current_log)\n",
    "\n",
    "    # Path for training log file\n",
    "    log_path = params[\"training_log_path\"]\n",
    "\n",
    "    # Try to load training log file\n",
    "    try:\n",
    "        with open(log_path, \"r\") as file:\n",
    "            last_log = json.load(file)\n",
    "        file.close()\n",
    "\n",
    "    # If file not found, create a new one\n",
    "    except FileNotFoundError as fe:\n",
    "        with open(log_path, \"w\") as file:\n",
    "            file.write(\"[]\")\n",
    "        file.close()\n",
    "\n",
    "        with open(log_path, \"r\") as file:\n",
    "            last_log = json.load(file)\n",
    "        file.close()\n",
    "    \n",
    "    # Add current log to previous log\n",
    "    last_log.append(current_log)\n",
    "\n",
    "    # Save updated log\n",
    "    with open(log_path, \"w\") as file:\n",
    "        json.dump(last_log, file)\n",
    "        file.close()\n",
    "\n",
    "    # Return log\n",
    "    return last_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c9b8b3-7d82-4cd5-a06f-fe3617c9a3dc",
   "metadata": {},
   "source": [
    "# 4. Training & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41790a5c-e5ed-4421-b3d5-cf55e980862e",
   "metadata": {},
   "source": [
    "### Create Model Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d4763f30-4742-457f-a465-651e86c7a5ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model_object(params: dict) -> list:\n",
    "    # Debug message\n",
    "    util.print_debug(\"Creating model objects.\")\n",
    "\n",
    "    # Create model objects\n",
    "    lgr = LogisticRegression()\n",
    "    dct = DecisionTreeClassifier()\n",
    "    rfc = RandomForestClassifier()\n",
    "    xgb = XGBClassifier()\n",
    "\n",
    "    # Create list of model\n",
    "    list_of_model = [\n",
    "        { \"model_name\": lgr.__class__.__name__, \"model_object\": lgr, \"model_uid\": \"\"},\n",
    "        { \"model_name\": dct.__class__.__name__, \"model_object\": dct, \"model_uid\": \"\"},\n",
    "        { \"model_name\": rfc.__class__.__name__, \"model_object\": rfc, \"model_uid\": \"\"},\\\n",
    "        { \"model_name\": xgb.__class__.__name__, \"model_object\": xgb, \"model_uid\": \"\"}\n",
    "    ]\n",
    "\n",
    "    # Debug message\n",
    "    util.print_debug(\"Model objects created.\")\n",
    "\n",
    "    # Return the list of model\n",
    "    return list_of_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a6d4b9-8e2a-4019-839c-d7f56020afe9",
   "metadata": {},
   "source": [
    "### Training Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0551c88-8fc9-44d7-8ab7-ca1562a3caa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_eval(configuration_model: str, params: dict, hyperparams_model: list = None):\n",
    "    # Load dataset\n",
    "    x_train, y_train, \\\n",
    "    x_valid, y_valid, \\\n",
    "    x_test, y_test = load_dataset(params)\n",
    "\n",
    "    # Variabel to store trained models\n",
    "    list_of_trained_model = dict()\n",
    "\n",
    "    # Create log template\n",
    "    training_log = training_log_template()\n",
    "\n",
    "    # Training for every data configuration\n",
    "    for config_data in x_train:\n",
    "        # Debug message\n",
    "        util.print_debug(\"Training model based on configuration data: {}\".format(config_data))\n",
    "\n",
    "        # Create model objects\n",
    "        if hyperparams_model == None:\n",
    "            list_of_model = create_model_object(params)\n",
    "        else:\n",
    "            list_of_model = copy.deepcopy(hyperparams_model)\n",
    "\n",
    "        # Variabel to store tained model\n",
    "        trained_model = list()\n",
    "\n",
    "        # Load train data based on its configuration\n",
    "        x_train_data = x_train[config_data]\n",
    "        y_train_data = y_train[config_data]\n",
    "\n",
    "        # Train each model by current dataset configuration\n",
    "        for model in list_of_model:\n",
    "            # Debug message\n",
    "            util.print_debug(\"Training model: {}\".format(model[\"model_name\"]))\n",
    "\n",
    "            # Training\n",
    "            training_time = util.time_stamp()\n",
    "            model[\"model_object\"].fit(x_train_data, y_train_data)\n",
    "            training_time = (util.time_stamp() - training_time).total_seconds()\n",
    "\n",
    "            # Debug message\n",
    "            util.print_debug(\"Evalutaing model: {}\".format(model[\"model_name\"]))\n",
    "\n",
    "            # Evaluation\n",
    "            y_predict = model[\"model_object\"].predict(x_valid)\n",
    "            performance = classification_report(y_valid, y_predict, output_dict = True)\n",
    "\n",
    "            # Debug message\n",
    "            util.print_debug(\"Logging: {}\".format(model[\"model_name\"]))\n",
    "\n",
    "            # Create UID\n",
    "            uid = hashlib.md5(str(training_time).encode()).hexdigest()\n",
    "\n",
    "            # Assign model's UID\n",
    "            model[\"model_uid\"] = uid\n",
    "\n",
    "            # Create training log data\n",
    "            training_log[\"model_name\"].append(\"{}-{}\".format(configuration_model, model[\"model_name\"]))\n",
    "            training_log[\"model_uid\"].append(uid)\n",
    "            training_log[\"training_time\"].append(training_time)\n",
    "            training_log[\"training_date\"].append(util.time_stamp())\n",
    "            training_log[\"performance\"].append(performance)\n",
    "            training_log[\"f1_score_avg\"].append(performance[\"macro avg\"][\"f1-score\"])\n",
    "            training_log[\"data_configurations\"].append(config_data)\n",
    "\n",
    "            # Collect current trained model\n",
    "            trained_model.append(copy.deepcopy(model))\n",
    "\n",
    "            # Debug message\n",
    "            util.print_debug(\"Model {} has been trained for configuration data {}.\".format(model[\"model_name\"], config_data))\n",
    "        \n",
    "        # Collect current trained list of model\n",
    "        list_of_trained_model[config_data] = copy.deepcopy(trained_model)\n",
    "    \n",
    "    # Debug message\n",
    "    util.print_debug(\"All combination models and configuration data has been trained.\")\n",
    "    \n",
    "    # Return list trained model\n",
    "    return list_of_trained_model, training_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "784eb3a4-03cb-436f-9b74-b80ed9c6ceeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time_stamp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m list_of_trained_model, training_log \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBaseline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 5\u001b[0m, in \u001b[0;36mtrain_eval\u001b[0;34m(configuration_model, params, hyperparams_model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_eval\u001b[39m(configuration_model: \u001b[38;5;28mstr\u001b[39m, params: \u001b[38;5;28mdict\u001b[39m, hyperparams_model: \u001b[38;5;28mlist\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Load dataset\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     x_train, y_train, \\\n\u001b[1;32m      4\u001b[0m     x_valid, y_valid, \\\n\u001b[0;32m----> 5\u001b[0m     x_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Variabel to store trained models\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     list_of_trained_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_dataset\u001b[39m(params: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Debug message\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_debug\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLoading dataset.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Load train set\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     x_train, y_train \u001b[38;5;241m=\u001b[39m load_train_feng(params)\n",
      "File \u001b[0;32m~/MLProcess/loan_approval_prediction/src/util.py:31\u001b[0m, in \u001b[0;36mprint_debug\u001b[0;34m(messages)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_debug\u001b[39m(messages: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# Check wheter user wants to use print or not\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m PRINT_DEBUG \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 31\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[43mtime_stamp\u001b[49m(), messages)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time_stamp' is not defined"
     ]
    }
   ],
   "source": [
    "list_of_trained_model, training_log = train_eval(\"Baseline\", params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
